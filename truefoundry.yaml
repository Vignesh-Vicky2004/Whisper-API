name: whisper-api
type: service
image:
  build_source:
    type: local
    local_build:
      dockerfile: Dockerfile
ports:
  - port: 8000
    host: 0.0.0.0
resources:
  memory: 6Gi
  cpu: 2000m
  ephemeral_storage: 10Gi
  # Add GPU resource for T4
  gpu:
    type: nvidia.com/gpu
    count: 1
requests:
  memory: 4Gi
  cpu: 1500m
  gpu:
    type: nvidia.com/gpu
    count: 1
env:
  - name: PYTHONUNBUFFERED
    value: "1"
  - name: CUDA_VISIBLE_DEVICES
    value: "0"
  - name: NVIDIA_VISIBLE_DEVICES
    value: "all"
  - name: NVIDIA_DRIVER_CAPABILITIES
    value: "compute,utility"
replicas:
  min: 1
  max: 2  # Reduced since GPU instances are expensive
health_check:
  http_get:
    path: /health
    port: 8000
  initial_delay_seconds: 90  # Increased for GPU model loading
  period_seconds: 10
  timeout_seconds: 5
  failure_threshold: 3
readiness_probe:
  http_get:
    path: /ready
    port: 8000
  initial_delay_seconds: 60  # Increased for GPU model loading
  period_seconds: 5
  timeout_seconds: 3
  failure_threshold: 5
# Node selector to ensure scheduling on GPU nodes
node_selector:
  accelerator: nvidia-tesla-t4
